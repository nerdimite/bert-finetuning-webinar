# BERT Fine-tuning with Pytorch and Transformers
### FullStack AI Series- Part 1 (CellStrat AI Lab)

This repository contains the code for BERT Fine-tuning using Pytorch and Transformers and is a part of the Full stack AI Love Coding Series at CellStrat AI Lab.

In this part, BERT was fine-tuned for Sentiment Analysis using the Transformers library by Hugging Face. Checkout the [notebook](BERT_Finetuning.ipynb) for steps and code implementation.

The recording of the webinar can be accessed 
[here](https://youtu.be/NoixdExFb7Y)

Checkout the code from the other parts here:

- [Part 2](https://github.com/theneuralbeing/bert-web-app)
- [Part 3](https://github.com/theneuralbeing/bert-deployment-aws)



## References
https://arxiv.org/abs/1810.04805

https://huggingface.co/transformers/

https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b
